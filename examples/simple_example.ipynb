{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-soccer",
   "metadata": {},
   "source": [
    "This notebook contains a very simple example of how to analyze your videos using flytracker (name will change). It's very minimal, but all you need to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flytracker import run\n",
    "from flytracker.analysis import annotate\n",
    "from flytracker.utils.param_helpers import load_frame, test_mask, test_threshold, test_blob_detector\n",
    "from flytracker.localization.blob import default_blob_detector_params\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of movie\n",
    "movie_path = \"../data/experiments/bruno/videos/seq_1.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-approach",
   "metadata": {},
   "source": [
    "The videos often contain the edges of the plate and sometimes QR codes. These mess with the detection, so we remove them by applying a mask. To check if we're using the right mask, we load a random frame, apply our mask and see how it looks. Let's use frame 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_frame(movie_path, frame=100, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-nylon",
   "metadata": {},
   "source": [
    "The mask is just an array of 1s and 0s with the same size of as the image, and 0 meaning we don't want to use the area. Below is how we build it, and we apply it to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones((1080, 1280), dtype=bool)\n",
    "mask[:130, :] = 0\n",
    "mask[-160:, :] = 0\n",
    "mask[:, :270] = 0\n",
    "mask[:, -205:] = 0\n",
    "\n",
    "mask[:190, :350] = 0\n",
    "mask[:195, -270:] = 0\n",
    "mask[-220:, :340] = 0\n",
    "mask[870:, 1010:] = 0\n",
    "\n",
    "masked_image = test_mask(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-universe",
   "metadata": {},
   "source": [
    "Let's see how it looks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(masked_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-holmes",
   "metadata": {},
   "source": [
    "Once the mask is good, we can check the blob detector, which decides how many flies and initializes the kmeans. We've chosen good defaults, but if you use very different setting (for example, 20 arenas), you might have to change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = test_blob_detector(masked_image, default_blob_detector_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(masked_image, cmap='gray')\n",
    "plt.scatter(*positions[:, ::-1].T, marker=\"x\", color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-atlas",
   "metadata": {},
   "source": [
    "Seems good. We also need to threshold the image to decide where the flies are. Typically we choose 120 as a threshold value which works well in most cases, but again, you might need to change a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 120\n",
    "thresholded_image = test_threshold(masked_image, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(thresholded_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-accuracy",
   "metadata": {},
   "source": [
    "Looks good again. We just need to supply the movie location, mask, and number of arenas. THe settings are if you want to use a GPU (3x speedup), parallel load, how many initial frames for the blob detector and the threshold. Most won't need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = run(\n",
    "    movie_path,\n",
    "    mask,\n",
    "    n_arenas=4,\n",
    "    gpu=True,\n",
    "    parallel=True,\n",
    "    n_ini=100,\n",
    "    threshold=threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-heaven",
   "metadata": {},
   "source": [
    "We save the dataframe to hdf using high compression; so that it doesn't become really big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"../tests/df.hdf\", key=\"df\", complevel=9, complib=\"blosc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-gasoline",
   "metadata": {},
   "source": [
    "Finally you can annotate, just give the dataframe and the movie location. Track_length says how long you want the paths to persist in seconds, and touching distance gives you a warning if flies get closer than this distance. \n",
    "\n",
    "Annotating is pretty slow, so I'd only do it to manually check if you see weird stuff in your trajectories or you're validating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(df, movie_path, \"../tests/annotated_video.mp4\", track_length=30, touching_distance=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-month",
   "metadata": {},
   "source": [
    "Normally you only need to do most of this once (except for the mask), and put it in a script instead of a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-nightmare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
