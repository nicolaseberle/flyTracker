{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "english-genome",
   "metadata": {},
   "source": [
    "In the previous notebook we saw that the parallel loading now works properly. Let's compare them to make sure they're similar, we can use that to build a test before we refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respective-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from flytracker.io.dataset import VideoDataset\n",
    "\n",
    "from flytracker.tracker import _run, _initialize, _localize\n",
    "from flytracker.preprocessing.preprocessing import  preprocessing_torch\n",
    "from flytracker.localization.blob import localize_blob, default_blob_detector_params\n",
    "from flytracker.localization.kmeans import localize_kmeans_torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = \"../../data/experiments/bruno/videos/seq_1.mp4\"\n",
    "\n",
    "mask = torch.ones((1080, 1280), dtype=bool)\n",
    "mask[:130, :] = 0\n",
    "mask[-160:, :] = 0\n",
    "mask[:, :270] = 0\n",
    "mask[:, -205:] = 0\n",
    "\n",
    "mask[:190, :350] = 0\n",
    "mask[:195, -270:] = 0\n",
    "mask[-220:, :340] = 0\n",
    "mask[870:, 1010:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contrary-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "after-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with frame 0\n",
      "Done with frame 1000\n",
      "Done with frame 2000\n",
      "Done with frame 3000\n",
      "Done with frame 4000\n",
      "Done with frame 5000\n",
      "Done with frame 6000\n",
      "Done with frame 7000\n",
      "Done with frame 8000\n",
      "Done with frame 9000\n",
      "Done with frame 10000\n",
      "CPU times: user 10min 6s, sys: 10.6 s, total: 10min 17s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = VideoDataset(movie_path, parallel=False)\n",
    "loader = DataLoader(dataset, batch_size=None, pin_memory=True)\n",
    "\n",
    "preprocessor_ini = preprocessing_torch(mask, torch.tensor(255, dtype=torch.uint8))\n",
    "initial_position, initial_frame = _initialize(loader, localize_blob, (default_blob_detector_params(), preprocessor_ini), 100)\n",
    "preprocessor_main= preprocessing_torch(mask.cuda(), torch.tensor(255, dtype=torch.uint8).cuda())\n",
    "\n",
    "locs_sequential = _localize(loader, localize_kmeans_torch, (preprocessor_main, 120, 'cuda'), initial_position, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-speaking",
   "metadata": {},
   "source": [
    "Now with the parallel loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blond-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with frame 0\n",
      "Done with frame 1000\n",
      "Done with frame 2000\n",
      "Done with frame 3000\n",
      "Done with frame 4000\n",
      "Done with frame 5000\n",
      "Done with frame 6000\n",
      "Done with frame 7000\n",
      "Done with frame 8000\n",
      "Done with frame 9000\n",
      "Done with frame 10000\n",
      "CPU times: user 7min 5s, sys: 6.54 s, total: 7min 11s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = VideoDataset(movie_path, parallel=True)\n",
    "loader = DataLoader(dataset, batch_size=None, pin_memory=True)\n",
    "\n",
    "preprocessor_ini = preprocessing_torch(mask, torch.tensor(255, dtype=torch.uint8))\n",
    "initial_position, initial_frame = _initialize(loader, localize_blob, (default_blob_detector_params(), preprocessor_ini), 100)\n",
    "preprocessor_main= preprocessing_torch(mask.cuda(), torch.tensor(255, dtype=torch.uint8).cuda())\n",
    "\n",
    "locs_parallel = _localize(loader, localize_kmeans_torch, (preprocessor_main, 120, 'cuda'), initial_position, 10000)\n",
    "dataset.reader.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-gross",
   "metadata": {},
   "source": [
    "Whooosh. Now lets compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partial-pension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch.stack(locs_parallel), torch.stack(locs_sequential))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-burke",
   "metadata": {},
   "source": [
    "Thats good enough. Great. Now let's turn it into a script for easy testing and then we can refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-friendly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
